I"|<p>In this post, I will attempt to rationalize my geometric intuition for Self-Attention used in Large Language Models.</p>
:ET